{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import *\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "from time import time\n",
    "from peaks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class analysis:\n",
    "    #   Get list of directories in the path starting with 's_'\n",
    "    def __init__(self, dataDirName = \"RSI40V90\", dataType = \"ppf/AD/\"):\n",
    "        self.dataDirName = dataDirName\n",
    "        self.dataType = dataType\n",
    "\n",
    "        self.dataPath = \"/data/kabir/output/\" + self.dataType + self.dataDirName\n",
    "        self.resultPath = \"/home/kabir/Project/tripartiteSynapse/results/\" + self.dataType + self.dataDirName\n",
    "\n",
    "    def getDirs(self, path, sstr='s_'):\n",
    "        dirs = [d for d in os.listdir(path) if os.path.isdir(path + '/' + d) and sstr in d]\n",
    "        dirs.sort()\n",
    "        return(dirs)\n",
    "    \n",
    "    def makeDirs(self):\n",
    "        if not os.path.exists(self.resultPath):\n",
    "            os.makedirs(self.resultPath)\n",
    "    \n",
    "    #   Average Over all Seeds\n",
    "    def avg_dat(self, inFile=\"/dat/ca.dat\", outFile=\"/ca.dat\"):\n",
    "        print(\"\\nCalculating Average of\", inFile)\n",
    "        print(self.dataDirName)\n",
    "\n",
    "        # Get list of directories in data path\n",
    "        dirs = self.getDirs(self.dataPath)\n",
    "        seeds = len(dirs)\n",
    "        print('seeds: ', seeds)\n",
    "\n",
    "        j=1\n",
    "        avg = np.genfromtxt(self.dataPath+'/'+dirs[0]+inFile)\n",
    "        l = len(avg)\n",
    "        for i in range(1, seeds):\n",
    "            temp = np.genfromtxt(self.dataPath+'/'+dirs[i]+inFile, invalid_raise=False)\n",
    "            if len(temp) != l:\n",
    "                l = len(temp)\n",
    "                print(i, dirs[i], l, temp[-1])\n",
    "            else:\n",
    "                avg += temp #genfromtxt(dataPath+'/'+dirs[i]+inFile)\n",
    "                j += 1\n",
    "        avg = avg/j #seeds\n",
    "        #print('j = ', j)\n",
    "        \n",
    "        self.makeDirs()\n",
    "        \n",
    "        of = self.resultPath + outFile\n",
    "        print(\"Writing average to: \" + of)\n",
    "        #print(avg)\n",
    "        np.savetxt(of, avg, fmt='%.6f')\n",
    "    \n",
    "    \n",
    "    def avg_dat2(self, inFile=\"/dat/ca.dat\", outFile=\"/ca.dat\"):\n",
    "        print(\"\\nCalculating Average of\", inFile)\n",
    "        print(self.dataDirName)\n",
    "        \n",
    "        # Get list of directories in data path\n",
    "        dirs = self.getDirs(self.dataPath)\n",
    "        seeds = len(dirs)\n",
    "        print('seeds: ', seeds)\n",
    "        \n",
    "        \n",
    "        times=np.genfromtxt(self.dataPath+'/'+dirs[0]+inFile, invalid_raise=False).T[0,:]\n",
    "        l=len(times)\n",
    "        avg=[]\n",
    "        for i in range(0, seeds):\n",
    "            temp = np.genfromtxt(self.dataPath+'/'+dirs[i]+inFile, invalid_raise=False)\n",
    "            if len(temp) != l:\n",
    "                l = len(temp)\n",
    "                print(i, dirs[i], l, temp[-1])\n",
    "            else:\n",
    "                avg.append(temp[:,1:].T)\n",
    "        \n",
    "        data = np.concatenate([np.array([a]).T for a in avg],axis=2)\n",
    "        print(data.shape)\n",
    "        average=np.sum(data,axis=2)/np.size(data,axis=2)\n",
    "        times=np.array(np.array([times]))\n",
    "        print(times.shape,average.T.shape)\n",
    "        complete_data=np.concatenate((times,average.T),axis=0).T\n",
    "        \n",
    "        self.makeDirs()\n",
    "        \n",
    "        of = self.resultPath + outFile\n",
    "        print(\"Writing average to: \" + of)\n",
    "        #print(avg)\n",
    "        np.savetxt(of, complete_data, fmt='%.6f')\n",
    "        \n",
    "    #   Ca Concentration Calculation\n",
    "    def conc_calc(self, step=5, inFile=\"/ca.dat\", outFile=\"/CaConc\"):\n",
    "        data = np.genfromtxt(self.resultPath + inFile, usecols=(0,1), unpack=True)\n",
    "        print(\"Calculating Calcium Concentration...\")\n",
    "\n",
    "        c_tc = np.multiply(data[0],data[1])\n",
    "        dt=step*(data[0][1]-data[0][0])\n",
    "        c_out = []\n",
    "        for i in range(0,len(data[0])-step-1,step):\n",
    "            c_out.append([data[0][i], (c_tc[i+step]-c_tc[i])/dt])\n",
    "        self.makeDirs()\n",
    "        print(\"Writing Ca Conc. to file:\" + outFile)\n",
    "        np.savetxt(self.resultPath + outFile, c_out, fmt='%.6f')\n",
    "\n",
    "\n",
    "\n",
    "    #avg_dat(inFile=\"/dat/ca.dat\", outFile=\"/ca.dat\")\n",
    "    #conc_calc(inFile=\"/ca.dat\", outFile=\"/CaConc\")\n",
    "\n",
    "    #   Get Vesicle Release Statistics for PPF\n",
    "    def relppf(self, isi, vdcc, resample=1000, tc=0.02): # isi in ms\n",
    "        n = 2 # number of AP\n",
    "        ts = [(i*isi+2.0)/1000.0 for i in range(n)]\n",
    "        alldirs = self.getDirs(self.dataPath)\n",
    "        ndirs = len(alldirs)\n",
    "        print('seeds: ', ndirs)\n",
    "\n",
    "        for d in [(self.dataPath + '/' + dir + '/dat/') for dir in alldirs]:\n",
    "            os.system(\"cd \" + d + \"; cat vdcc.* > rel.dat\")\n",
    "\n",
    "        prs = []\n",
    "        for r in range(resample):\n",
    "            if (r+1)%100==0: print('resampling:', r+1)\n",
    "            x=[randint(0,ndirs-1) for p in range(0,ndirs)]\n",
    "            dirs = [alldirs[i] for i in x]\n",
    "\n",
    "            nRel = np.zeros(n) # [Rel1, Rel2,... Reln]\n",
    "            pr = []\n",
    "            cp = np.zeros(4) # [P00, P01, P10, P11]\n",
    "            for d in [(self.dataPath + '/' + dir + '/dat/') for dir in dirs]:\n",
    "                fpath = (d + \"/rel.dat\")\n",
    "                f = open(fpath, 'r')\n",
    "\n",
    "                #   Get no. of vesicles released after AP specified by ts\n",
    "                temp = np.zeros(n)\n",
    "                p = [0, 0]\n",
    "                time = 0\n",
    "                for line in f:\n",
    "                    time = float(line.strip(\"\\n\").split(\" \")[0])\n",
    "                    for i in range(len(ts)):\n",
    "                        if (time>ts[i] and time<ts[i]+tc):\n",
    "                            temp[i] = 1\n",
    "\n",
    "                    for i in range(len(ts)):\n",
    "                        if (time>ts[i] and time<ts[i]+tc):\n",
    "                            p[i] = 1\n",
    "\n",
    "                for i in range(n):\n",
    "                    if temp[i] == 1: nRel[i] += 1\n",
    "\n",
    "\n",
    "                # Calculate Conditional Release Probabilities\n",
    "                if(p[0]==0 and p[1]==0): cp[0] += 1\n",
    "                if(p[0]==0 and p[1]==1): cp[1] += 1\n",
    "                if(p[0]==1 and p[1]==0): cp[2] += 1\n",
    "                if(p[0]==1 and p[1]==1): cp[3] += 1\n",
    "\n",
    "\n",
    "            #print('num of rel', cp)\n",
    "            cp = [float(i)/ndirs for i in cp]\n",
    "            #print('fraction of rel', cp)\n",
    "            pp = [cp[0]/(cp[0]+cp[1]), cp[1]/(cp[0]+cp[1]), cp[2]/(cp[2]+cp[3]), cp[3]/(cp[2]+cp[3])]\n",
    "            #print('pp: ', pp)\n",
    "\n",
    "            for i in range(n):\n",
    "                pr.append(nRel[i]/float(len(dirs)))\n",
    "            for i in range(1,n):\n",
    "                pr.append(pr[i]/pr[0])\n",
    "\n",
    "\n",
    "            for i in range(4):\n",
    "                pr.append(pp[i])\n",
    "\n",
    "            #print('pr: ', pr)\n",
    "            prs.append(pr)\n",
    "\n",
    "        m = np.mean(prs, axis=0)\n",
    "        s = np.std(prs, axis=0)\n",
    "\n",
    "        self.makeDirs()\n",
    "\n",
    "        result = np.concatenate((np.array(list(zip(m,s))).flatten(),[isi, vdcc]), axis=0)\n",
    "        result = list(result)\n",
    "        print('Vesicle release stats:\\n', result)\n",
    "        header = 'p1\\tep1\\t\\tp2\\t\\tep2\\t\\tppr\\t\\teppr\\tP00\\t\\teP00\\tP01\\t\\teP01\\tP10\\t\\teP10\\tP11\\t\\teP11\\tISI\\tVDCC\\n'\n",
    "        np.savetxt(self.resultPath + '/result', [result], header=header, fmt=['%0.4f']*14+['%d']*2, delimiter=\"\\t\")\n",
    "\n",
    "        os.system(\"cat \" + self.dataPath + \"/*/dat/rel.dat > \" + self.resultPath + \"/vesRel\")\n",
    "        os.system(\"cat \" + self.dataPath + \"/*/dat/vdcc.async_*.dat > \" + self.resultPath + \"/asyncRel\")\n",
    "        os.system(\"cat \" + self.dataPath + \"/*/dat/vdcc.sync_*.dat > \" + self.resultPath + \"/syncRel\")\n",
    "\n",
    "\n",
    "    #isi = int(dataDirName.split(\"I\")[1].split(\"V\")[0])\n",
    "    #vdcc = int(dataDirName.split(\"V\")[1])\n",
    "    #print('isi: ', isi, '\\nvdcc: ', vdcc)\n",
    "\n",
    "    #relppf(isi, vdcc, resample=1000)\n",
    "    def relptp(self, freq, n=20, resample=1000, tc=0.02): # isi in ms\n",
    "        ts = [i/freq+0.002 for i in range(n)]\n",
    "        alldirs = self.getDirs(dataPath)\n",
    "        ndirs = len(alldirs)\n",
    "        print('seeds: ', ndirs)\n",
    "\n",
    "        for d in [(self.dataPath + '/' + dir + '/dat/') for dir in alldirs]:\n",
    "            if not os.path.exists(d+'/rel.dat'):\n",
    "                os.system(\"cd \" + d + \"; cat vdcc.* > rel.dat\")\n",
    "\n",
    "        prs = []\n",
    "        for r in range(resample):\n",
    "            if (r+1)%100==0: print('resampling:', r+1)\n",
    "            x=[randint(0,ndirs-1) for p in range(0,ndirs)]\n",
    "            dirs = [alldirs[i] for i in x]\n",
    "\n",
    "            nRel = [0]*len(ts) # [Rel1, Rel2,... Reln]\n",
    "            pr = []\n",
    "            for d in [(self.dataPath + '/' + dir + '/dat/') for dir in dirs]:\n",
    "                fpath = (d + \"/rel.dat\")\n",
    "                f = open(fpath,'r')\n",
    "\n",
    "                #   Get no. of vesicles released after AP specified by ts\n",
    "                for line in f:\n",
    "                    time = float(line.strip(\"\\n\").split(\" \")[0])\n",
    "                    for i in range(len(ts)):\n",
    "                        if (time>ts[i] and time<ts[i]+tc):\n",
    "                            nRel[i] += 1\n",
    "\n",
    "            for i in range(n):\n",
    "                pr.append(nRel[i]/float(len(dirs)))\n",
    "            for i in range(n):\n",
    "                pr.append(pr[i]/pr[0])\n",
    "\n",
    "            prs.append(pr)\n",
    "\n",
    "        m = np.mean(prs, axis=0)\n",
    "        s = np.std(prs, axis=0)\n",
    "\n",
    "        os.system(\"cat \" + self.dataPath + \"/*/dat/rel.dat > \" + self.resultPath + \"/vesRel\")\n",
    "        os.system(\"cat \" + self.dataPath + \"/*/dat/vdcc.async_*.dat > \" + self.resultPath + \"/asyncRel\")\n",
    "        os.system(\"cat \" + self.dataPath + \"/*/dat/vdcc.sync_*.dat > \" + self.resultPath + \"/syncRel\")\n",
    "\n",
    "        if not os.path.exists(self.resultPath):\n",
    "            print('asdf')\n",
    "            os.system(\"mkdir \" + self.resultPath)\n",
    "\n",
    "        #   Print Results\n",
    "        r = self.resultPath + '/result'\n",
    "        np.savetxt(r, list(zip(range(1,n+1),m[:n],s[:n],m[n:],s[n:])), \\\n",
    "        fmt=['%d','%0.4f','%0.4f','%0.4f','%0.4f'], delimiter=\"\\t\")\n",
    "\n",
    "        #print(np.array(list(zip(range(1,n+1),m[:n],s[:n],m[n:],s[n:]))))\n",
    "\n",
    "\n",
    "    def caStat(self,outFile='/caStat.dat', showFig=False):\n",
    "        data = np.genfromtxt(self.resultPath + '/CaConc', unpack=True)\n",
    "        #print data\n",
    "\n",
    "        pk = detect_peaks(data[1], mph=2, mpd=360, threshold=0, show=showFig)\n",
    "        pkValue = [data[1][i] for i in pk]\n",
    "        pkTime = [data[0][i] for i in pk]\n",
    "\n",
    "        cumVal = []\n",
    "        dt = data[0][1]-data[0][0]\n",
    "        for p in [p-30 for p in pk]:\n",
    "            dataChunk = data[1][p:p+400]\n",
    "            cumVal.append(simps(dataChunk, dx=dt))\n",
    "            #plt.plot(data[0][p:p+400], dataChunk)\n",
    "        #plt.show()\n",
    "        \n",
    "        isi = int(self.dataDirName.split(\"I\")[1].split(\"V\")[0])\n",
    "        vdcc = int(self.dataDirName.split(\"V\")[1])\n",
    "        print('isi: ', isi, '\\nvdcc: ', vdcc)\n",
    "        #print(range(1,len(pk)+1), pkTime, pkValue)\n",
    "        data = np.array(list(zip(pkTime, pkValue, cumVal))).flatten()\n",
    "        print('Ca stats:\\n', data)\n",
    "        data = np.concatenate([data, [isi, vdcc]])\n",
    "        print('Ca stats:\\n', data)\n",
    "\n",
    "        header = 't_pk1\\tpk1\\t\\tc_pk1\\tt_pk2\\tpk2\\t\\tc_pk2\\tISI\\tVDCC\\n'\n",
    "        self.makeDirs()\n",
    "        np.savetxt(self.resultPath + outFile, [data], fmt=['%0.4f','%0.2f','%0.4f']*2+['%d']*2, header=header, delimiter='\\t')\n",
    "        \n",
    "\n",
    "    def caStat_ptp(self,outFile='/caStat.dat', showFig=False):\n",
    "        data = np.genfromtxt(self.resultPath + '/CaConc', unpack=True)\n",
    "        #print data\n",
    "\n",
    "        pk = detect_peaks(data[1], mph=2, mpd=360, threshold=0, show=showFig)\n",
    "        pkValue = [data[1][i] for i in pk]\n",
    "        pkTime = [data[0][i] for i in pk]\n",
    "\n",
    "        cumVal = []\n",
    "        dt = data[0][1]-data[0][0]\n",
    "        for p in [p-30 for p in pk]:\n",
    "            dataChunk = data[1][p:p+400]\n",
    "            cumVal.append(simps(dataChunk, dx=dt))\n",
    "            #plt.plot(data[0][p:p+400], dataChunk)\n",
    "        #plt.show()\n",
    "        \n",
    "        \n",
    "        #print(range(1,len(pk)+1), pkTime, pkValue)\n",
    "        data = np.array(list(zip(pkTime, pkValue, cumVal))).flatten()\n",
    "        data = np.concatenate([data, [isi, vdcc]])\n",
    "        print('Ca stats:\\n', data)\n",
    "\n",
    "        header = 't_pk1\\tpk1\\t\\tc_pk1\\tt_pk2\\tpk2\\t\\tc_pk2\\tISI\\tVDCC\\n'\n",
    "        self.makeDirs()\n",
    "        np.savetxt(self.resultPath + outFile, [data], fmt=['%0.4f','%0.2f','%0.4f']*2+['%d']*2, header=header, delimiter='\\t')\n",
    "\n",
    "\n",
    "    #caStat(showFig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Average of /dat/ca.dat\n",
      "RSI40V90\n",
      "seeds:  500\n",
      "(7001, 3, 500)\n",
      "(1, 7001) (3, 7001)\n",
      "Writing average to: /home/kabir/Project/tripartiteSynapse/results/ppf/AD/RSI40V90/ca.dat\n",
      "13.479039907455444\n"
     ]
    }
   ],
   "source": [
    "a=\"\"\"import time\n",
    "start=time.time()\n",
    "M=analysis()\n",
    "M.avg_dat2()\n",
    "stop=time.time()\n",
    "print(stop-start)\n",
    "#13.364609718322754\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5001) (1, 5001)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 5.80000000e+01, 5.87200000e+03],\n",
       "       [1.00000000e-05, 0.00000000e+00, 5.60000000e+01, 5.87300000e+03],\n",
       "       [2.00000000e-05, 0.00000000e+00, 5.50000000e+01, 5.87300000e+03],\n",
       "       ...,\n",
       "       [4.99800000e-02, 1.31554213e+00, 2.09000000e+02, 5.91800000e+03],\n",
       "       [4.99900000e-02, 1.31527897e+00, 2.11000000e+02, 5.91500000e+03],\n",
       "       [5.00000000e-02, 1.31501591e+00, 2.10000000e+02, 5.91600000e+03]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.genfromtxt(\"/data/kabir/output/ppf/R150control/RSI20V120/s_00001/dat/ca.dat\")[:,1:].T\n",
    "b=np.genfromtxt(\"/data/kabir/output/ppf/R150control/RSI20V120/s_00001/dat/ca.dat\")[:,0].T\n",
    "b=np.array(np.array([b]))\n",
    "print(a.shape,b.shape)\n",
    "\n",
    "np.concatenate((b,a),axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5002"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i+1\n",
    "file_len(\"/data/kabir/output/ppf/R150control/RSI20V120/s_00001/dat/ca.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
